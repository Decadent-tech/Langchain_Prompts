{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Runnable Sequence"
      ],
      "metadata": {
        "id": "92V-A-UpNLwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Set the API key as an environment variable\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key"
      ],
      "metadata": {
        "id": "fF1F3TIMOaBN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAf9X4fPK2E7",
        "outputId": "f463f1bb-ea19-4641-a5d7-3d4cc082bc39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This joke plays on the dual meaning of the word \"byte.\" In the context of computers and technology, a byte is a unit of digital information. However, in the joke, \"byte\" is used as a pun for \"bit,\" which sounds like \"bites.\" The AI broke up with its supercomputer girlfriend because she couldn't handle his small and probably cheesy \"byte\" sized jokes, meaning his jokes were too corny or not funny enough for her taste.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableSequence\n",
        "from google.colab import userdata\n",
        "\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "prompt1 = PromptTemplate(\n",
        "    template='Write a joke about {topic}',\n",
        "    input_variables=['topic']\n",
        ")\n",
        "\n",
        "model = ChatOpenAI(api_key=openai_api_key)\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "prompt2 = PromptTemplate(\n",
        "    template='Explain the following joke - {text}',\n",
        "    input_variables=['text']\n",
        ")\n",
        "\n",
        "chain = RunnableSequence(prompt1, model, parser, prompt2, model, parser)\n",
        "\n",
        "print(chain.invoke({'topic':'AI'}))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runnable Parallel"
      ],
      "metadata": {
        "id": "42W6mpjfSK6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.runnables import RunnableSequence, RunnableParallel # Added RunnableParallel import\n",
        "from google.colab import userdata # Import userdata\n",
        "\n",
        "# Load environment variables - this might not be needed if using Colab secrets\n",
        "# load_dotenv()\n",
        "\n",
        "# Fetch API key from Colab secrets\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "prompt1 = PromptTemplate(\n",
        "    template='Generate a tweet about {topic}',\n",
        "    input_variables=['topic']\n",
        ")\n",
        "\n",
        "prompt2 = PromptTemplate(\n",
        "    template='Generate a Linkedin post about {topic}',\n",
        "    input_variables=['topic']\n",
        ")\n",
        "\n",
        "# Pass the API key to ChatOpenAI\n",
        "model = ChatOpenAI(api_key=openai_api_key)\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "parallel_chain = RunnableParallel({\n",
        "    'tweet': RunnableSequence(prompt1, model, parser),\n",
        "    'linkedin': RunnableSequence(prompt2, model, parser)\n",
        "})\n",
        "\n",
        "result = parallel_chain.invoke({'topic':'AI'})\n",
        "\n",
        "print(\"Tweet:\")\n",
        "print(result['tweet'])\n",
        "print(\"\\nLinkedIn Post:\")\n",
        "print(result['linkedin'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYFts4qrOos_",
        "outputId": "3161f31c-1ff8-45e8-b087-046e2254c325"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet:\n",
            "\"Exciting to see how AI continues to revolutionize industries from healthcare to finance. The possibilities are endless! #AI #technology\"\n",
            "\n",
            "LinkedIn Post:\n",
            "Exciting news in the world of AI! The latest advancements in artificial intelligence are revolutionizing industries and creating new opportunities for innovation and growth. From machine learning to natural language processing, AI is shaping the future of technology. Stay ahead of the curve and embrace the power of AI in your business today. #AI #ArtificialIntelligence #Innovation #TechTrends #FutureOfWork.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runnable Passthrough"
      ],
      "metadata": {
        "id": "a-6GxwBwSO5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.runnables import RunnableSequence, RunnableParallel, RunnablePassthrough # Corrected import path\n",
        "from google.colab import userdata # Import userdata\n",
        "\n",
        "# Load environment variables - this might not be needed if using Colab secrets\n",
        "# load_dotenv()\n",
        "\n",
        "# Fetch API key from Colab secrets\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "prompt1 = PromptTemplate(\n",
        "    template='Write a joke about {topic}',\n",
        "    input_variables=['topic']\n",
        ")\n",
        "\n",
        "model = ChatOpenAI(api_key=openai_api_key)\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "prompt2 = PromptTemplate(\n",
        "    template='Explain the following joke - {text}',\n",
        "    input_variables=['text']\n",
        ")\n",
        "\n",
        "joke_gen_chain = RunnableSequence(prompt1, model, parser)\n",
        "\n",
        "parallel_chain = RunnableParallel({\n",
        "    'joke': RunnablePassthrough(),\n",
        "    'explanation': RunnableSequence(prompt2, model, parser)\n",
        "})\n",
        "\n",
        "final_chain = RunnableSequence(joke_gen_chain, parallel_chain)\n",
        "\n",
        "print(final_chain.invoke({'topic':'cricket'}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uQwfyfKSb7M",
        "outputId": "53372dcb-5999-49b0-de90-70d83b550732"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'joke': 'Why did the cricket team go to the bank?\\n\\nTo make a good deposit!', 'explanation': 'This joke plays on the word \"deposit,\" which can mean both adding money to a bank account and the act of placing a cricket ball in a specific spot during a game. In this case, the joke implies that the cricket team went to the bank not to add money, but to make a good deposit by placing the cricket ball in a strategic position on the pitch during the game.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runnable Lambda"
      ],
      "metadata": {
        "id": "5-Jr-8-rTAmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableSequence, RunnableLambda, RunnablePassthrough, RunnableParallel # Corrected import path\n",
        "from google.colab import userdata # Import userdata\n",
        "\n",
        "# Fetch API key from Colab secrets\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "def word_count(text):\n",
        "    return len(text.split())\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template='Write a joke about {topic}',\n",
        "    input_variables=['topic']\n",
        ")\n",
        "\n",
        "# Pass the API key to ChatOpenAI\n",
        "model = ChatOpenAI(api_key=openai_api_key)\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "joke_gen_chain = RunnableSequence(prompt, model, parser)\n",
        "\n",
        "parallel_chain = RunnableParallel({\n",
        "    'joke': RunnablePassthrough(),\n",
        "    'word_count': RunnableLambda(word_count)\n",
        "})\n",
        "\n",
        "final_chain = RunnableSequence(joke_gen_chain, parallel_chain)\n",
        "\n",
        "result = final_chain.invoke({'topic':'AI'})\n",
        "\n",
        "final_result = \"\"\"{} \\n word count - {}\"\"\".format(result['joke'], result['word_count'])\n",
        "\n",
        "print(final_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D08Vrfa0TC5M",
        "outputId": "519b91d6-f8e7-4761-e211-adf727bf9ede"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the AI break up with his girlfriend?\n",
            "\n",
            "He couldn't handle her emotional baggage! \n",
            " word count - 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rnnable Branch"
      ],
      "metadata": {
        "id": "VTQW9Kc5T4jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.runnables import RunnableSequence, RunnableParallel, RunnablePassthrough, RunnableBranch, RunnableLambda # Corrected import path\n",
        "from google.colab import userdata # Import userdata\n",
        "\n",
        "# Fetch API key from Colab secrets\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# load_dotenv() # No longer needed when using userdata\n",
        "\n",
        "prompt1 = PromptTemplate(\n",
        "    template='Write a detailed report on {topic}',\n",
        "    input_variables=['topic']\n",
        ")\n",
        "\n",
        "prompt2 = PromptTemplate(\n",
        "    template='Summarize the following text \\n {text}',\n",
        "    input_variables=['text']\n",
        ")\n",
        "\n",
        "model = ChatOpenAI(api_key=openai_api_key) # Pass the API key\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "report_gen_chain = RunnableSequence(prompt1, model , parser)\n",
        "\n",
        "branch_chain = RunnableBranch(\n",
        "    (lambda x: len(x.split())>300, RunnableSequence(prompt2 , model ,parser)),\n",
        "    RunnablePassthrough()\n",
        ")\n",
        "\n",
        "final_chain = RunnableSequence(report_gen_chain, branch_chain)\n",
        "\n",
        "print(final_chain.invoke({'topic':'Russia vs Ukraine'}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RvIGQJIUN2r",
        "outputId": "6ff39ea8-8db9-4e2e-85fe-12fb61d87280"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The relationship between Russia and Ukraine is complex and tumultuous, with tensions escalating since the 2014 annexation of Crimea by Russia. The annexation led to a sharp deterioration in relations and sparked the War in Donbass between pro-Russian separatists and the Ukrainian government. The conflict has caused thousands of deaths and strained diplomatic relations between the two countries. The international community has called for a peaceful resolution, but progress has been slow. The situation is further complicated by Russia's presence in Crimea and ongoing war of words. It is crucial for both sides to work towards a peaceful resolution to avoid further bloodshed and instability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LECL"
      ],
      "metadata": {
        "id": "6eMr9tO-U10g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.runnables import RunnableSequence, RunnableParallel, RunnablePassthrough, RunnableBranch, RunnableLambda # Corrected import path\n",
        "from google.colab import userdata # Import userdata\n",
        "\n",
        "# Fetch API key from Colab secrets\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# load_dotenv() # No longer needed when using userdata\n",
        "\n",
        "prompt1 = PromptTemplate(\n",
        "    template='Write a detailed report on {topic}',\n",
        "    input_variables=['topic']\n",
        ")\n",
        "\n",
        "prompt2 = PromptTemplate(\n",
        "    template='Summarize the following text \\n {text}',\n",
        "    input_variables=['text']\n",
        ")\n",
        "\n",
        "model = ChatOpenAI(api_key=openai_api_key) # Pass the API key\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "report_gen_chain = prompt1 | model | parser\n",
        "\n",
        "branch_chain = RunnableBranch(\n",
        "    (lambda x: len(x.split())>300, prompt2 | model | parser),\n",
        "    RunnablePassthrough()\n",
        ")\n",
        "\n",
        "final_chain = RunnableSequence(report_gen_chain, branch_chain)\n",
        "\n",
        "print(final_chain.invoke({'topic':'Russia vs Ukraine'}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krDy1TT1T7S0",
        "outputId": "caa2d70f-7090-4d93-d6a6-15004211ad25"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The conflict between Russia and Ukraine has deep historical roots dating back to Ukraine's independence from Russia in 1991. Tensions escalated due to Ukraine's move towards European integration and NATO membership, leading to key events such as the annexation of Crimea in 2014 and the downing of Malaysia Airlines Flight MH17. The conflict remains unresolved with sporadic fighting in eastern Ukraine and strained relations between the two countries. Progress has been made, but lasting peace will require political will, compromise, and dialogue from both sides. Until then, the conflict poses a threat to regional security and stability.\n"
          ]
        }
      ]
    }
  ]
}